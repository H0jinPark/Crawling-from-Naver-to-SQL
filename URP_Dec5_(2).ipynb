{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew3PI3VNI3ng",
        "outputId": "cd38e906-e889-45fa-cec6-06854a04b7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkg66eVNEPoG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from konlpy.tag import Okt\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel, LdaModel\n",
        "import re\n",
        "import gensim.corpora as corpora\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.metrics import silhouette_score\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "negGV_AELj_S",
        "outputId": "d1f3868d-c477-4665-b28e-3667711136c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data = pd.read_csv('/content/drive/MyDrive/URP/Questions_old.csv')\n",
        "stop_words = pd.read_csv('/content/drive/MyDrive/URP/stopwords-ko.txt')\n",
        "# Rename the columns\n",
        "data.rename(columns={'제목': 'title', '질문': 'questions'}, inplace=True)\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJoAlx-fFDVq",
        "outputId": "ac7fed50-77fb-4037-e08a-e265e0c9eebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['문서 번호', 'title', 'questions', '위치 고유번호', '조회수', '질문 날짜'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define preprocessing function for cleaning Korean text\n",
        "def preprocess_text_korean(text):\n",
        "    \"\"\"\n",
        "    Preprocess Korean text by:\n",
        "    - Removing extra spaces\n",
        "    - Keeping only Korean, English, and spaces\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Handle NaN values\n",
        "        return \"\"\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    text = re.sub(r'[^\\uAC00-\\uD7A3a-zA-Z\\s]', ' ', text)  # Keep only Korean, English, and spaces\n",
        "    return text.strip()\n",
        "\n",
        "# Step 2: Combine title and questions columns for preprocessing\n",
        "# Assuming 'title' and 'questions' are the columns to process\n",
        "data['combined_text'] = data['title'] + \" \" + data['questions']  # Combine title and questions columns\n",
        "\n",
        "# Step 3: Apply text preprocessing to the combined text\n",
        "data['cleaned_text'] = data['combined_text'].apply(preprocess_text_korean)\n",
        "\n",
        "# Step 4: Define tokenization function using Okt tokenizer\n",
        "def preprocess_korean(text):\n",
        "    \"\"\"\n",
        "    Tokenize Korean text into nouns while removing common stopwords.\n",
        "    \"\"\"\n",
        "    okt = Okt()  # Initialize the Okt tokenizer\n",
        "    # Define common stopwords to remove from the tokenized text\n",
        "    common_words = {'질문', '곳', '제', '요', '좀', '어디', '저', '분', '수', '중',\n",
        "                   '정도', '시', '있나요', '알려주세요', '있을까요', '하는데', '혹시'}\n",
        "    # Extract nouns and filter out stopwords or single-character tokens\n",
        "    nouns = [n for n in okt.nouns(str(text)) if n not in common_words and len(n) > 1]\n",
        "    return nouns\n",
        "\n",
        "# Step 5: Analyze community topics using LDA\n",
        "def analyze_community_topics(data, num_topics=6):\n",
        "    \"\"\"\n",
        "    Perform LDA topic modeling on the community questions and calculate a silhouette score.\n",
        "\n",
        "    Steps:\n",
        "    - Preprocess and tokenize text\n",
        "    - Create a dictionary and corpus for LDA\n",
        "    - Train the LDA model\n",
        "    - Calculate the silhouette score to evaluate topic separability\n",
        "    - Retrieve top terms and example questions for each topic\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 5.1: Process documents for topic modeling\n",
        "    docs = []\n",
        "    raw_docs = []\n",
        "    for text in data['cleaned_text']:\n",
        "        if pd.notna(text):\n",
        "            tokens = preprocess_korean(text)\n",
        "            if len(tokens) > 3:\n",
        "                docs.append(tokens)\n",
        "                raw_docs.append(text)\n",
        "\n",
        "    # Step 5.2: Create dictionary and corpus for LDA\n",
        "    dictionary = corpora.Dictionary(docs)\n",
        "    dictionary.filter_extremes(no_below=5, no_above=0.3)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
        "\n",
        "    # Step 5.3: Train the LDA model\n",
        "    lda_model = models.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=num_topics,\n",
        "        random_state=42,\n",
        "        passes=20,\n",
        "        alpha='symmetric'\n",
        "    )\n",
        "\n",
        "    # Step 5.4: Calculate silhouette score to evaluate topic clustering\n",
        "    # Get the topic distribution for each document\n",
        "    doc_topics = [lda_model.get_document_topics(doc, minimum_probability=0.0) for doc in corpus]\n",
        "    # Convert topic distributions into a dense matrix\n",
        "    topic_vectors = np.array([[prob for _, prob in sorted(doc)] for doc in doc_topics])\n",
        "    # Assign each document to its dominant topic\n",
        "    dominant_topics = np.argmax(topic_vectors, axis=1)\n",
        "    # Compute the silhouette score\n",
        "    silhouette_avg = silhouette_score(topic_vectors, dominant_topics, metric='cosine')\n",
        "\n",
        "    # Step 5.5: Extract top terms and example documents for each topic\n",
        "    topics_info = []\n",
        "    for topic_id in range(num_topics):\n",
        "        # Get the top terms for the topic\n",
        "        top_terms = lda_model.show_topic(topic_id, topn=10)\n",
        "\n",
        "        # Find example documents for the topic\n",
        "        topic_docs = []\n",
        "        for doc_id, doc_bow in enumerate(corpus):\n",
        "            topic_dist = lda_model.get_document_topics(doc_bow)\n",
        "            doc_topic_probs = dict(topic_dist)\n",
        "            if topic_id in doc_topic_probs and doc_topic_probs[topic_id] > 0.4:  # Filter based on topic probability\n",
        "                topic_docs.append((raw_docs[doc_id], doc_topic_probs[topic_id]))\n",
        "\n",
        "        # Sort and select top 3 example documents\n",
        "        topic_docs.sort(key=lambda x: x[1], reverse=True)\n",
        "        examples = topic_docs[:3]\n",
        "\n",
        "        # Append the topic information\n",
        "        topics_info.append({\n",
        "            'terms': top_terms,\n",
        "            'examples': examples\n",
        "        })\n",
        "\n",
        "    return topics_info, silhouette_avg\n",
        "\n",
        "# Step 6: Run topic analysis on the dataset\n",
        "topics_info, silhouette_score = analyze_community_topics(data)\n",
        "\n",
        "# Step 7: Display the results\n",
        "print(f\"Silhouette Score: {silhouette_score:.3f}\\n\")\n",
        "print(\"Community Question Topics:\\n\")\n",
        "for idx, topic in enumerate(topics_info, 1):\n",
        "    print(f\"\\nTopic {idx}:\")\n",
        "    print(\"Key Terms:\")\n",
        "    terms = [(term, f\"{prob:.3f}\") for term, prob in topic['terms']]\n",
        "    print(\", \".join([f\"{term}({prob})\" for term, prob in terms]))\n",
        "\n",
        "    print(\"\\nExample Questions:\")\n",
        "    for text, prob in topic['examples']:\n",
        "        print(f\"- [{prob:.2f}] {text[:100]}...\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zGFqJeZHJWj",
        "outputId": "c3a2325a-b947-48d4-e335-d49906b5c09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.596\n",
            "\n",
            "Community Question Topics:\n",
            "\n",
            "\n",
            "Topic 1:\n",
            "Key Terms:\n",
            "전주(0.051), 임플란트(0.051), 치과(0.046), 시술(0.034), 김제(0.018), 기숙사(0.017), 추천(0.016), 익산(0.015), 병원(0.014), 여수(0.013)\n",
            "\n",
            "Example Questions:\n",
            "- [0.96] 질문김제 백구면에 임플란트 시술 중 환자의 구강 상태에 맞    김제 백구면에 임플란트 시술 중 환자의 구강 상태에 맞춘 맞춤형 치료를 제공하는 치과가 있나요...\n",
            "- [0.96] 질문김제시 요촌동       번지의 영문 표기 Daum지도에서 살펴보니 전라북도 김제시 요촌동       번지 는 향교길 골목길에 접해있는 단독주택입니다  김제시 요촌동      ...\n",
            "- [0.95] 질문전주 삼천동에서 임플란트 시술 후 환자 맞춤형 회복 계    전주 삼천동에서 임플란트 시술 후 환자 맞춤형 회복 계획을 제공하는 치과는 어디인가요...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Topic 2:\n",
            "Key Terms:\n",
            "고등학교(0.043), 학교(0.034), 내신(0.021), 지역(0.016), 여고(0.015), 학원(0.015), 중학교(0.013), 전학(0.012), 학생(0.010), 학년(0.010)\n",
            "\n",
            "Example Questions:\n",
            "- [0.98] 질문부산 사직고등학교 이사벨고등학교 저는 중  여학생인데요 중학교는 널널하고 빡센편은 아닌 학교에 진학중이에요 내신성적 퍼센테이지는        정도입니당 여고는 부산진여고 성모여...\n",
            "- [0.97] 질문군산여고랑 영광여고에 대해 알려주세요 군산여고와 영광여고중에서 어디를 갈지 고민하는 중 입니다  이 두 학교에 대해서 질문이 있습니다    군산여고 내신따기어렵다는데 얼마나 어...\n",
            "- [0.97] 질문연천중 중 여학생 해운대쪽 고등학교 진학 도와주세요   제가 생각하는 고등학교는 해강고부흥고양운고입니다 제가 궁금한거는   각 학교의 입학 퍼센트   각 학교별로 체육복등교가 ...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Topic 3:\n",
            "Key Terms:\n",
            "사람(0.022), 청주(0.022), 친구(0.021), 해몽(0.016), 생각(0.012), 그냥(0.009), 저희(0.008), 계속(0.008), 무슨(0.008), 포항(0.008)\n",
            "\n",
            "Example Questions:\n",
            "- [0.96] 질문꿈 해몽해주세요 제발    내 뒤에도 어떤 사람이 있고 저 멀리에도 다른 사람이 있는데 멀리있는 사람이 몸을 엄청 꾸기고있고 뒤에 있는 사람이 뭐라고 하고 뒤에 있는 사람이 저...\n",
            "- [0.96] 질문아버지가 몸이 안좋은상태로 꿈에나온 꿈해몽 부탁드려요 올초 시아버지라유친정 아버지가 같은달에 돌아가셨어요 시아버님은 뇌경색이있어서 몸이 마비증세가 있었고 친정아버지도 몸이 안좋...\n",
            "- [0.96] 질문작년에 썸탔던 사람이 꿈에 나왔어요 안녕하세요 오늘 꿈을 꾸고 일어났는데 뭔가 묘한 느낌이 들어서요 작년  월쯤에 썸탔던 한살 연상 오빠가 있는데 꿈에서 그 오빠랑 다시 아무일...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Topic 4:\n",
            "Key Terms:\n",
            "버스(0.061), 시간(0.035), 타고(0.015), 터미널(0.014), 하나요(0.010), 방법(0.010), 김해(0.010), 창원(0.008), 카드(0.008), 도착(0.007)\n",
            "\n",
            "Example Questions:\n",
            "- [0.97] 질문교동짬뽕 원조 술먹다 내기를 했는데 교동짬뽕 원조가 속초인가요 강릉인가요  네이버에 쳐보니 교동에서 시작된게 교동짬뽕이라던데 속초에 있는게 교동이거든요  근데 지금의 그 유명한...\n",
            "- [0.97] 질문창원    번    번 버스 시간 김해 살고 서울가는 버스가  시   분이라 창원종합터미널 까지 버스 타고 가야하는데요 그때까지 도착할려면 새벽  시쯤에    번 버스 타야하는...\n",
            "- [0.96] 질문김해    번 버스 시간표    김해    번 버스 시간표 새벽부터 저녁까지 시간표 알려주실수 있으실까요  광남 백조아파트    하단역 환승센터 시간표 하단역 환승센터    광...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Topic 5:\n",
            "Key Terms:\n",
            "추천(0.052), 근처(0.037), 맛집(0.019), 군산(0.016), 아파트(0.013), 아시(0.012), 카페(0.011), 장소(0.010), 식당(0.009), 주변(0.009)\n",
            "\n",
            "Example Questions:\n",
            "- [0.97] 질문신촌 이자카야 술집 하나마토 신촌점 하이볼 맛집인가요  신촌 이자카야 술집 하나마토 신촌점이 하이볼 맛집으로 유명하다고 해서 가보려고 하는데 하이볼 맛이 어떤지 궁금합니다  다...\n",
            "- [0.97] 질문강서구 스몰 웨딩 장소 어디가 좋을까요  강서구에서 스몰 웨딩을 준비 중인 예비신부입니다  양가 부모님과 가까운 친지들만 모시고 소규모로 결혼식을 진행하고 싶은데 강서구에 괜찮...\n",
            "- [0.97] 질문정자역 고기집 제주 클래식 맛집 주차 어디에 하나요  정자역에 고기 맛집인 제주 클래식에서 식사를 할 예정인데 여기는 주차를 어디에 하나요  전용 주차장이 있는지 주차권을 주시...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Topic 6:\n",
            "Key Terms:\n",
            "천안(0.054), 축제(0.021), 공원(0.017), 사람(0.014), 서울(0.014), 한강(0.012), 제주도(0.012), 내일(0.011), 아산(0.009), 여의도(0.009)\n",
            "\n",
            "Example Questions:\n",
            "- [0.97] 질문천안눈썹문신 디자인 잘하는 곳 천안눈썹문신 샵 좀 추천해주세요  디자인 잘하는 곳으로 알아보고 있는데 어디가 천안눈썹문신 잘하나요  그동안 눈썹문신 받으면 항상 디자인이 아쉬워...\n",
            "- [0.97] 질문     여의도한강공원 불꽃축제 지방인이 올해 불꽃축제를 여의도한강공원에서 보려고 합니다  처음이라 뭘 잘 몰라 몇가지 질문드려요     여의도한강공원에서 돗자리 피고 관람하려...\n",
            "- [0.96] 질문여의도 불꽃축제 오늘 친구들과 불꽃축제를 보러갈건데 사실 불꽃축제가 메인이 아니고 그냥 서울로 놀러갈겸 보는거라 명당급으로 안보여도 되거든요  원래는 남산타워 등반해서 보려고 ...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}